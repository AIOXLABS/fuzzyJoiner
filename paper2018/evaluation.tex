\section{Evaluation}
\label{results}

Table\ref{Characteristics} quantifies the difficulty of the metric problem for the people and company data in Wikidata.  After conversion to character embeddings, we computed the 20 nearest neighbors for each anchor, and computed what percentage of positives were found within the top 20 (recall), the average distance of positives and negatives from the anchor and their standard deviations respectively.  To compare it with metric learning for face recognition, which has been studied before, we also provide the same metrics for Labeled Faces in the Wild based on their input vector embeddings.  The table quantifies the difficulty of the metric learning problem across different data types, with positive distances for each being greater than negative distances.  Baseline recall rates are also poor, which is important if one needs to establish that the neural network did in fact learn after training.

\begin{table}[ht]
\caption{Dataset characteristics}
\label{Characteristics}
\begin{tabular}{l|r|r|r|r|r|r|r|}
\hline
Entity Type & Recall & Positives Avg. & Positives Std. & Max Positives & Negatives Avg. & Negatives Std. & Negatives Max \\
People & 0.03 & 9.07 & 3.05 & 28.30 & 3.16 & 1.17 & 16.97 \\
Companies & 0.20 & 4.67 & 2.29 & 19.21 & 3.18 & 1.40 & 12.77 \\
Faces & 0.037 & 39.82 & 9.17 & 79.15 & 25.05 & 3.72 & 43.19 \\
\end{tabular}
\end{table}

Table\ref{Evaluation} shows the same metrics after training.  Because we compared across different losses, the results are catagorized by each loss function for each dataset we tested.  For each value reported in the table, we conducted two runs to ensure the results were stable across runs, and we report the mean in the table.

\begin{table}[ht]
\caption{Results for people and companies by loss functions}
\label{Evaluation}
\begin{tabular}{l|l|r|r|r|r|r|r|r|r|}
\hline
Entity Type & Loss Function & Recall & Precision & Positives Avg. & Positives Std. & Max Positives & Negatives Avg. & Negatives Std. & Negatives Max \\
\hline
\multirow{4}{*}{People} & Our loss & .81 & .93 & .69 & .53 & 21.08 & 2.39 & 1.27 & 33.46 \\
\hline
& Triplet loss & .73 & .91 & .38 & .13 & .84 & .54 & .1 & .86 \\
\hline
& Improved loss & NA & NA & NA & NA & NA & NA & NA & NA \\
\hline
& Angular loss & NA & NA & NA & NA & NA & NA & NA & NA \\
\hline
\multirow{4}{*}{Companies} & Our loss & NA & NA & NA & NA & NA & NA & NA & NA \\
& Triplet loss & NA & NA & NA & NA & NA & NA & NA & NA \\
\hline
& Improved loss & NA & NA & NA & NA & NA & NA & NA & NA \\
\hline
& Angular loss & NA & NA & NA & NA & NA & NA & NA & NA \\
\hline
\end{tabular}
\end{table}

